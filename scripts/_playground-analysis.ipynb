{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ca7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.colors as mc  # For the legend\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pypsa\n",
    "import calendar\n",
    "\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from pypsa.descriptors import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select run & Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_configuration(config_path):\n",
    "    \"\"\"\n",
    "    Load configuration settings from a YAML file.\n",
    "    \"\"\"\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "\n",
    "snakemake_config = load_configuration(\"../config.yaml\")\n",
    "snakemake.input = Dict()\n",
    "snakemake.output = Dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = \"test-IEDK-1H-cfe100-allflex\"  # run name from config.yaml\n",
    "\n",
    "if True:\n",
    "    folder = f\"/results/{run}\"\n",
    "    scenario = \"/2025/IEDK/p1/cfe100\"\n",
    "\n",
    "    snakemake.input.data = f\"{folder}/networks/{scenario}/40.nc\"\n",
    "    snakemake.output.plot = f\"{folder}/plots/plot.pdf\"\n",
    "\n",
    "    n = pypsa.Network(f\"../{folder}/networks/{scenario}/40.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.generators_t.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c913f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display two dataframes containing the time series\n",
    "df = n.generators_t.p_max_pu.filter(regex=\"Ireland|Denmark\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    n.generators_t.p_max_pu.filter(regex=\"Ireland|Denmark\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"snapshot\"})\n",
    "    .assign(snapshot=lambda x: pd.to_datetime(x[\"snapshot\"]))\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64f70a",
   "metadata": {},
   "source": [
    "### Visualise time-series of RES feed-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_heatmap_data(df, month, location, carrier, scaling):\n",
    "    data = df[df[\"snapshot\"].dt.month == month]\n",
    "    day = data[\"snapshot\"].dt.day\n",
    "    value = data[f\"{location} {carrier}\"].values.reshape(\n",
    "        int(24 / scaling), len(day.unique()), order=\"F\"\n",
    "    )\n",
    "    return day, value\n",
    "\n",
    "\n",
    "def draw_heatmap(ax, day, value, scaling, colormap, min_val, max_val):\n",
    "    xgrid = np.arange(day.max() + 1) + 1  # for days\n",
    "    ygrid = np.arange(int(24 / scaling) + 1)  # for hours\n",
    "\n",
    "    # Ensure the dimensions of 'value' match the expected dimensions for 'xgrid' and 'ygrid'\n",
    "    if value.shape != (len(ygrid) - 1, len(xgrid) - 1):\n",
    "        raise ValueError(\n",
    "            f\"Shape of value ({value.shape}) does not match xgrid ({len(xgrid)}) and ygrid ({len(ygrid)}) dimensions.\"\n",
    "        )\n",
    "\n",
    "    ax.pcolormesh(xgrid, ygrid, value, cmap=colormap, vmin=min_val, vmax=max_val)\n",
    "    ax.set_ylim(int(24 / scaling), 0)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def plot_heatmap_cf(\n",
    "    df,\n",
    "    location,\n",
    "    carrier,\n",
    "    scaling,\n",
    "    colormap,\n",
    "    min_val,\n",
    "    max_val,\n",
    "    year=2013,\n",
    "    figsize=(14, 5),\n",
    "):\n",
    "    fig, axes = plt.subplots(1, 12, figsize=figsize, sharey=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    for month, ax in enumerate(axes, start=1):\n",
    "        day, value = prepare_heatmap_data(df, month, location, carrier, scaling)\n",
    "        draw_heatmap(ax, day, value, scaling, colormap, min_val, max_val)\n",
    "        ax.set_title(calendar.month_abbr[month], fontsize=10, pad=3)\n",
    "\n",
    "    fig.subplots_adjust(\n",
    "        left=0.05, right=0.98, top=0.9, hspace=0.08, wspace=0.1, bottom=0.15\n",
    "    )\n",
    "    cbar_ax = fig.add_axes([0.3, 0.08, 0.4, 0.04])\n",
    "    norm = mc.Normalize(min_val, max_val)\n",
    "    cb = fig.colorbar(\n",
    "        ScalarMappable(norm=norm, cmap=colormap), cax=cbar_ax, orientation=\"horizontal\"\n",
    "    )\n",
    "    cb.set_label(\"Hourly Capacity Factor (%)\", size=14)\n",
    "\n",
    "    fig.text(0.12, 0.12, \"Day of the Month\", ha=\"center\", va=\"center\", fontsize=14)\n",
    "    fig.text(\n",
    "        0.04,\n",
    "        0.34,\n",
    "        \"Hour of the Day\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        rotation=\"vertical\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    annotations = [\n",
    "        f\"Location: {location}\",\n",
    "        f\"Carrier: {carrier}\",\n",
    "        f\"Weather Year: {year}\",\n",
    "        r\"Unit: MWhÂ·h$^{-1}$\",\n",
    "    ]\n",
    "    for i, annotation in enumerate(annotations):\n",
    "        fig.text(\n",
    "            0.95,\n",
    "            0.12 - i * 0.05,\n",
    "            annotation,\n",
    "            ha=\"right\",\n",
    "            va=\"center\",\n",
    "            fontsize=14,\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "    fig.savefig(\"test.pdf\", bbox_inches=\"tight\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"Denmark\"\n",
    "carrier = \"solar\"\n",
    "scaling = int(snakemake.config[\"time_sampling\"][0])  # temporal scaling -- 3/1 for 3H/1H\n",
    "colormap = \"cividis\"  # https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "MIN, MAX = 0.0, 1.0  #  df[\"denmark onwind\"].min()\n",
    "\n",
    "plot_heatmap_cf(df, location, carrier, scaling, colormap, MIN, MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad04ae7a",
   "metadata": {},
   "source": [
    "### Difference in hourly RES potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa49b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[(df[\"snapshot\"].dt.month == 1)]\n",
    "value = data[f\"Denmark {carrier}\"] - data[f\"Ireland {carrier}\"]\n",
    "value.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN = -1.0  # df[\"denmark onwind\"].min() #case of cf -> 0\n",
    "MAX = 1.0  # df[\"denmark onwind\"].max() #case of cf -> 1\n",
    "colormap = \"RdBu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9364d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_diff(data, month, year, ax):\n",
    "    data = df[(df[\"snapshot\"].dt.month == month)]\n",
    "\n",
    "    snapshot = data[\"snapshot\"]\n",
    "    day = data[\"snapshot\"].dt.day\n",
    "    value = data[f\"Denmark {carrier}\"] - data[f\"Ireland {carrier}\"]\n",
    "    value = value.values.reshape(\n",
    "        int(24 / scaling), len(day.unique()), order=\"F\"\n",
    "    )  # 8 clusters of 3h in each day\n",
    "\n",
    "    xgrid = (\n",
    "        np.arange(day.max() + 1) + 1\n",
    "    )  # The inner + 1 increases the length, the outer + 1 ensures days start at 1, and not at 0\n",
    "    ygrid = np.arange(int(24 / scaling) + 1)  # hours (sampled or not) + extra 1\n",
    "\n",
    "    ax.pcolormesh(xgrid, ygrid, value, cmap=colormap, vmin=MIN, vmax=MAX)\n",
    "    # Invert the vertical axis\n",
    "    ax.set_ylim(int(24 / scaling), 0)\n",
    "    # Set tick positions for both axes\n",
    "    ax.yaxis.set_ticks([])  # [i for i in range(int(24/scaling))]\n",
    "    ax.xaxis.set_ticks([])\n",
    "    # Remove ticks by setting their length to 0\n",
    "    ax.yaxis.set_tick_params(length=0)\n",
    "    ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "    # Remove all spines\n",
    "    ax.set_frame_on(False)\n",
    "\n",
    "\n",
    "def plot_heatmap_cfdiff():\n",
    "    # Here 1 row year/variable and 12 columns for month\n",
    "    fig, axes = plt.subplots(1, 12, figsize=(14, 5), sharey=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    for i, year in enumerate([2013]):\n",
    "        for j, month in enumerate(range(1, 13)):\n",
    "            # print(f'j: {j}, month: {month}')\n",
    "            heatmap_diff(df, month, year, axes[j])\n",
    "\n",
    "    # Adjust margin and space between subplots (extra space is on the left for a label)\n",
    "    fig.subplots_adjust(\n",
    "        left=0.05, right=0.98, top=0.9, hspace=0.08, wspace=0\n",
    "    )  # wspace=0 stacks individual months together but easy to split\n",
    "\n",
    "    # some room for the legend in the bottom\n",
    "    fig.subplots_adjust(bottom=0.2)\n",
    "\n",
    "    # Create a new axis to contain the color bar\n",
    "    # Values are: (x coordinate of left border, y coordinate for bottom border, width, height)\n",
    "    cbar_ax = fig.add_axes([0.3, 0.03, 0.4, 0.04])\n",
    "\n",
    "    # Create a normalizer that goes from minimum to maximum value\n",
    "    norm = mc.Normalize(MIN, MAX)  # for CFE, otherwise (MIN, MAX)\n",
    "\n",
    "    # Create the colorbar and set it to horizontal\n",
    "    cb = fig.colorbar(\n",
    "        ScalarMappable(norm=norm, cmap=colormap),\n",
    "        cax=cbar_ax,  # Pass the new axis\n",
    "        orientation=\"horizontal\",\n",
    "    )\n",
    "\n",
    "    # Remove tick marks and set label\n",
    "    cb.ax.xaxis.set_tick_params(size=0)\n",
    "    cb.set_label(f\"{carrier} hourly capacity factor difference\", size=12)\n",
    "\n",
    "    # add some figure labels and title\n",
    "    fig.text(0.5, 0.15, \"Days of year\", ha=\"center\", va=\"center\", fontsize=14)\n",
    "    fig.text(\n",
    "        0.03,\n",
    "        0.5,\n",
    "        \"Hours of a day\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        rotation=\"vertical\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    fig.suptitle(\n",
    "        f\"Resource potential diff |  Denmark/Ireland datacenter pair\",\n",
    "        fontsize=20,\n",
    "        y=0.98,\n",
    "    )\n",
    "\n",
    "    # path = snakemake.output.plot.split('capacity.pdf')[0] + f'heatmaps'\n",
    "    # if not os.path.exists(path):\n",
    "    #    os.makedirs(path)\n",
    "\n",
    "    fig.savefig(\"test.pdf\", bbox_inches=\"tight\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc41cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap_cfdiff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df383d2",
   "metadata": {},
   "source": [
    "### Hmm.. let's take a look at correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_nb(n, node):\n",
    "    \"\"\"\n",
    "    Retrieve nodal energy balance per hour\n",
    "        -> lines and links are bidirectional AND their subsets are exclusive.\n",
    "        -> links include fossil gens\n",
    "    NB {-1} multiplier is a nodal balance sign\n",
    "    \"\"\"\n",
    "\n",
    "    components = [\"Generator\", \"Load\", \"StorageUnit\", \"Store\", \"Link\", \"Line\"]\n",
    "    nodal_balance = pd.DataFrame(index=n.snapshots)\n",
    "\n",
    "    for i in components:\n",
    "        if i == \"Generator\":\n",
    "            node_generators = n.generators.query(\"bus==@node\").index\n",
    "            nodal_balance = nodal_balance.join(n.generators_t.p[node_generators])\n",
    "        if i == \"Load\":\n",
    "            node_loads = n.loads.query(\"bus==@node\").index\n",
    "            nodal_balance = nodal_balance.join(-1 * n.loads_t.p_set[node_loads])\n",
    "        if i == \"Link\":\n",
    "            node_export_links = n.links.query(\"bus0==@node\").index\n",
    "            node_import_links = n.links.query(\"bus1==@node\").index\n",
    "            nodal_balance = nodal_balance.join(-1 * n.links_t.p0[node_export_links])\n",
    "            nodal_balance = nodal_balance.join(-1 * n.links_t.p1[node_import_links])\n",
    "            ##################\n",
    "        if i == \"StorageUnit\":\n",
    "            # node_storage_units = n.storage_units.query('bus==@node').index\n",
    "            # nodal_balance = nodal_balance.join(n.storage_units_t.p_dispatch[node_storage_units])\n",
    "            # nodal_balance = nodal_balance.join(n.storage_units_t.p_store[node_storage_units])\n",
    "            continue\n",
    "        if i == \"Line\":\n",
    "            continue\n",
    "        if i == \"Store\":\n",
    "            continue\n",
    "\n",
    "    nodal_balance = nodal_balance.rename(columns=rename).groupby(level=0, axis=1).sum()\n",
    "\n",
    "    # Custom groupby function\n",
    "    def custom_groupby(column_name):\n",
    "        if column_name.startswith(\"vcc\"):\n",
    "            return \"spatial shift\"\n",
    "        return column_name\n",
    "\n",
    "    # Apply custom groupby function\n",
    "    nodal_balance = nodal_balance.groupby(custom_groupby, axis=1).sum()\n",
    "\n",
    "    # revert nodal balance sign for display\n",
    "    if \"spatial shift\" in nodal_balance.columns:\n",
    "        nodal_balance[\"spatial shift\"] = nodal_balance[\"spatial shift\"] * -1\n",
    "    if \"temporal shift\" in nodal_balance.columns:\n",
    "        nodal_balance[\"temporal shift\"] = nodal_balance[\"temporal shift\"] * -1\n",
    "\n",
    "    return nodal_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f20ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacenters = snakemake.config[\"ci\"][\"datacenters\"]\n",
    "locations = list(datacenters.keys())\n",
    "names = list(datacenters.values())\n",
    "spatial_shift = retrieve_nb(n, names[1]).get(\"spatial shift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f\"Denmark {carrier}\"][:720].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_shift[:720].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d344e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive shift -> sending jobs AWAY; negative shift -> receiving jobs\n",
    "# for Denmark\n",
    "spatial_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50924c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive value -> Denmark is better resources; negative values -> Ireland has better resources\n",
    "value = df[f\"Denmark {carrier}\"] - df[f\"Ireland {carrier}\"]\n",
    "value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4645e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficient\n",
    "corr_matrix = np.corrcoef(spatial_shift, -value)\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed27ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Assuming value and spatial_shift are your data arrays\n",
    "correlation_coefficient, p_value = stats.pearsonr(spatial_shift, -value)\n",
    "\n",
    "print(f\"Correlation Coefficient: {correlation_coefficient}\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711537a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(df[f\"Denmark {carrier}\"], df[f\"Ireland {carrier}\"])\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a434f8e182fb5d5bd2581d74c958656c6d21213b4f6f091d4b0226e3d000e88a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
