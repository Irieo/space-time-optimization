{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ca7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.colors as mc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pypsa\n",
    "import calendar\n",
    "\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from pypsa.descriptors import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select run & Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_configuration(config_path):\n",
    "    \"\"\"\n",
    "    Load configuration settings from a YAML file.\n",
    "    \"\"\"\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "\n",
    "snakemake = Dict()\n",
    "snakemake.config = load_configuration(\"../config.yaml\")\n",
    "snakemake.input = Dict()\n",
    "snakemake.output = Dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = \"test-IEDK-1H-cfe100-allflex\"  # run name from config.yaml\n",
    "\n",
    "if True:\n",
    "    folder = f\"/results/{run}\"\n",
    "    scenario = \"/2025/IEDK/p1/cfe100\"\n",
    "\n",
    "    snakemake.input.data = f\"{folder}/networks/{scenario}/40.nc\"\n",
    "    snakemake.output.plot = f\"{folder}/plots/plot.pdf\"\n",
    "\n",
    "    n = pypsa.Network(f\"../{folder}/networks/{scenario}/40.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.generators_t.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c913f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display two dataframes containing the time series\n",
    "df = n.generators_t.p_max_pu.filter(regex=\"Ireland|Denmark\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    n.generators_t.p_max_pu.filter(regex=\"Ireland|Denmark\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"snapshot\"})\n",
    "    .assign(snapshot=lambda x: pd.to_datetime(x[\"snapshot\"]))\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64f70a",
   "metadata": {},
   "source": [
    "### Visualise time-series of RES feed-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_heatmap_data(df, month, location, carrier, scaling, diff_location=None):\n",
    "    data = df[df[\"snapshot\"].dt.month == month]\n",
    "    day = data[\"snapshot\"].dt.day\n",
    "    value = data[f\"{location} {carrier}\"].values\n",
    "\n",
    "    if diff_location:\n",
    "        diff_value = data[f\"{diff_location} {carrier}\"].values\n",
    "        value -= diff_value  # Subtracting the second time-series from the first\n",
    "\n",
    "    value = value.reshape(int(24 / scaling), len(day.unique()), order=\"F\")\n",
    "    return day, value\n",
    "\n",
    "\n",
    "def draw_heatmap(ax, day, value, scaling, colormap, min_val, max_val):\n",
    "    xgrid = np.arange(day.max() + 1) + 1  # for days\n",
    "    ygrid = np.arange(int(24 / scaling) + 1)  # for hours\n",
    "\n",
    "    # Ensure the dimensions of 'value' match the expected dimensions for 'xgrid' and 'ygrid'\n",
    "    if value.shape != (len(ygrid) - 1, len(xgrid) - 1):\n",
    "        raise ValueError(\n",
    "            f\"Shape of value ({value.shape}) does not match xgrid ({len(xgrid)}) and ygrid ({len(ygrid)}) dimensions.\"\n",
    "        )\n",
    "\n",
    "    ax.pcolormesh(xgrid, ygrid, value, cmap=colormap, vmin=min_val, vmax=max_val)\n",
    "    ax.set_ylim(int(24 / scaling), 0)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def plot_heatmap_cf(\n",
    "    df,\n",
    "    location,\n",
    "    carrier,\n",
    "    scaling,\n",
    "    colormap,\n",
    "    min_val,\n",
    "    max_val,\n",
    "    year=2013,\n",
    "    figsize=(14, 5),\n",
    "    plot_difference=False,\n",
    "    diff_location=None,\n",
    "):\n",
    "    fig, axes = plt.subplots(1, 12, figsize=figsize, sharey=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    for month, ax in enumerate(axes, start=1):\n",
    "        # Pass additional parameters if plotting the difference\n",
    "        day, value = prepare_heatmap_data(\n",
    "            df,\n",
    "            month,\n",
    "            location,\n",
    "            carrier,\n",
    "            scaling,\n",
    "            diff_location=diff_location if plot_difference else None,\n",
    "        )\n",
    "        draw_heatmap(ax, day, value, scaling, colormap, min_val, max_val)\n",
    "        ax.set_title(calendar.month_abbr[month], fontsize=10, pad=3)\n",
    "\n",
    "    fig.subplots_adjust(\n",
    "        left=0.05, right=0.98, top=0.9, hspace=0.08, wspace=0.1, bottom=0.15\n",
    "    )\n",
    "    cbar_ax = fig.add_axes([0.3, 0.08, 0.4, 0.04])\n",
    "    norm = mc.Normalize(min_val, max_val)\n",
    "    cb = fig.colorbar(\n",
    "        ScalarMappable(norm=norm, cmap=colormap), cax=cbar_ax, orientation=\"horizontal\"\n",
    "    )\n",
    "    cb.set_label(\"Hourly Capacity Factor (%)\", size=14)\n",
    "\n",
    "    fig.text(0.12, 0.12, \"Day of the Month\", ha=\"center\", va=\"center\", fontsize=14)\n",
    "    fig.text(\n",
    "        0.04,\n",
    "        0.34,\n",
    "        \"Hour of the Day\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        rotation=\"vertical\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    annotations = [\n",
    "        f\"Location: {location}\"\n",
    "        if not plot_difference\n",
    "        else f\"Location: {location} vs {diff_location}\",\n",
    "        f\"Carrier: {carrier}\",\n",
    "        f\"Weather Year: {year}\",\n",
    "        r\"Unit: MWhÂ·h$^{-1}$\",\n",
    "    ]\n",
    "    for i, annotation in enumerate(annotations):\n",
    "        fig.text(\n",
    "            0.95,\n",
    "            0.12 - i * 0.05,\n",
    "            annotation,\n",
    "            ha=\"right\",\n",
    "            va=\"center\",\n",
    "            fontsize=14,\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "    fig.savefig(\"test.pdf\", bbox_inches=\"tight\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"Ireland\"\n",
    "carrier = \"onwind\"\n",
    "scaling = int(snakemake.config[\"time_sampling\"][0])  # temporal scaling -- 3/1 for 3H/1H\n",
    "colormap = \"RdBu\"  # \"cividis\" # \"RdBu\"  # https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "MIN, MAX = -1, 1  #  df[\"denmark onwind\"].min()\n",
    "\n",
    "plot_heatmap_cf(\n",
    "    df,\n",
    "    location,\n",
    "    carrier,\n",
    "    scaling,\n",
    "    colormap,\n",
    "    MIN,\n",
    "    MAX,\n",
    "    diff_location=\"Denmark\",\n",
    "    plot_difference=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df383d2",
   "metadata": {},
   "source": [
    "### Hmm.. let's take a look at correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_nb(n, node):\n",
    "    \"\"\"\n",
    "    Retrieve nodal energy balance per hour\n",
    "        -> lines and links are bidirectional AND their subsets are exclusive.\n",
    "        -> links include fossil gens\n",
    "    NB {-1} multiplier is a nodal balance sign\n",
    "    \"\"\"\n",
    "\n",
    "    components = [\"Generator\", \"Load\", \"StorageUnit\", \"Store\", \"Link\", \"Line\"]\n",
    "    nodal_balance = pd.DataFrame(index=n.snapshots)\n",
    "\n",
    "    for i in components:\n",
    "        if i == \"Generator\":\n",
    "            node_generators = n.generators.query(\"bus==@node\").index\n",
    "            nodal_balance = nodal_balance.join(n.generators_t.p[node_generators])\n",
    "        if i == \"Load\":\n",
    "            node_loads = n.loads.query(\"bus==@node\").index\n",
    "            nodal_balance = nodal_balance.join(-1 * n.loads_t.p_set[node_loads])\n",
    "        if i == \"Link\":\n",
    "            node_export_links = n.links.query(\"bus0==@node\").index\n",
    "            node_import_links = n.links.query(\"bus1==@node\").index\n",
    "            nodal_balance = nodal_balance.join(-1 * n.links_t.p0[node_export_links])\n",
    "            nodal_balance = nodal_balance.join(-1 * n.links_t.p1[node_import_links])\n",
    "            ##################\n",
    "        if i == \"StorageUnit\":\n",
    "            # node_storage_units = n.storage_units.query('bus==@node').index\n",
    "            # nodal_balance = nodal_balance.join(n.storage_units_t.p_dispatch[node_storage_units])\n",
    "            # nodal_balance = nodal_balance.join(n.storage_units_t.p_store[node_storage_units])\n",
    "            continue\n",
    "        if i == \"Line\":\n",
    "            continue\n",
    "        if i == \"Store\":\n",
    "            continue\n",
    "\n",
    "    nodal_balance = nodal_balance.rename(columns=rename).groupby(level=0, axis=1).sum()\n",
    "\n",
    "    # Custom groupby function\n",
    "    def custom_groupby(column_name):\n",
    "        if column_name.startswith(\"vcc\"):\n",
    "            return \"spatial shift\"\n",
    "        return column_name\n",
    "\n",
    "    # Apply custom groupby function\n",
    "    nodal_balance = nodal_balance.groupby(custom_groupby, axis=1).sum()\n",
    "\n",
    "    # revert nodal balance sign for display\n",
    "    if \"spatial shift\" in nodal_balance.columns:\n",
    "        nodal_balance[\"spatial shift\"] = nodal_balance[\"spatial shift\"] * -1\n",
    "    if \"temporal shift\" in nodal_balance.columns:\n",
    "        nodal_balance[\"temporal shift\"] = nodal_balance[\"temporal shift\"] * -1\n",
    "\n",
    "    return nodal_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f20ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacenters = snakemake.config[\"ci\"][\"datacenters\"]\n",
    "locations = list(datacenters.keys())\n",
    "names = list(datacenters.values())\n",
    "spatial_shift = retrieve_nb(n, names[1]).get(\"spatial shift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f\"Denmark {carrier}\"][:720].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_shift[:720].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d344e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive shift -> sending jobs AWAY; negative shift -> receiving jobs\n",
    "# for Denmark\n",
    "spatial_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50924c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive value -> Denmark is better resources; negative values -> Ireland has better resources\n",
    "value = df[f\"Denmark {carrier}\"] - df[f\"Ireland {carrier}\"]\n",
    "value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4645e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficient\n",
    "corr_matrix = np.corrcoef(spatial_shift, -value)\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed27ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Assuming value and spatial_shift are your data arrays\n",
    "correlation_coefficient, p_value = stats.pearsonr(spatial_shift, -value)\n",
    "\n",
    "print(f\"Correlation Coefficient: {correlation_coefficient}\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711537a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(df[f\"Denmark {carrier}\"], df[f\"Ireland {carrier}\"])\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
