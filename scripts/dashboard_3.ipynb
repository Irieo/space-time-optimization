{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"PDF\")\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.colors as mc\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import pypsa\n",
    "import calendar\n",
    "from pypsa.descriptors import Dict\n",
    "\n",
    "from cartopy import crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load scenario and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_configuration(config_path):\n",
    "    \"\"\"\n",
    "    Load configuration settings from a YAML file.\n",
    "    \"\"\"\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "\n",
    "snakemake = Dict()\n",
    "snakemake.config = load_configuration(\"../config.yaml\")\n",
    "snakemake.input = Dict()\n",
    "snakemake.output = Dict()\n",
    "\n",
    "run = \"paper-DKGRPT-1H-allflex-noexcess-nocostshifts\"  # run name from config.yaml\n",
    "distance = \"DKGRPT\"  # pair name from config.yaml\n",
    "\n",
    "if True:\n",
    "    folder = f\"/results/{run}\"\n",
    "    scenario = f\"/2025/p1/cfe100/{distance}\"\n",
    "\n",
    "    snakemake.input.data = f\"{folder}/networks/{scenario}/40.nc\"\n",
    "    snakemake.output.plot = f\"{folder}/plots/plot.pdf\"\n",
    "\n",
    "    n = pypsa.Network(f\"../{folder}/networks/{scenario}/40.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacenters = snakemake.config[\"ci\"][f\"{distance}\"][\"datacenters\"]\n",
    "locations = list(datacenters.keys())\n",
    "names = list(datacenters.values())\n",
    "\n",
    "regions = gpd.read_file(\"../input/regions_onshore_elec_s_256.geojson\")\n",
    "n_256 = pypsa.Network(\"../input/elec_s_256_ec.nc\")\n",
    "\n",
    "df = pd.read_csv(f\"..{folder}/csvs{scenario}/summary.csv\", index_col=0, header=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = list(snakemake.config[\"ci\"][f\"{distance}\"][\"datacenters\"].values())\n",
    "location0 = locations[0]\n",
    "location1 = locations[1]\n",
    "location2 = locations[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wildcards & Settings\n",
    "config = snakemake.config\n",
    "policy = \"cfe100\"\n",
    "palette = \"p1\"\n",
    "zone = snakemake.config[\"zone\"]\n",
    "year = \"2025\"\n",
    "datacenters = config[\"ci\"][f\"{distance}\"][\"datacenters\"]\n",
    "locations = list(datacenters.keys())\n",
    "names = list(datacenters.values())\n",
    "\n",
    "flexibilities = snakemake.config[\"scenario\"][\"flexibility\"]\n",
    "\n",
    "# techs for CFE hourly matching, extracted from palette\n",
    "palette_techs = (\n",
    "    [\"onwind\", \"solar\"],\n",
    "    [\"battery\"],\n",
    "    [\"battery charger\"],\n",
    "    [\"battery discharger\"],\n",
    ")\n",
    "\n",
    "(\n",
    "    clean_techs,\n",
    "    storage_techs,\n",
    "    storage_charge_techs,\n",
    "    storage_discharge_techs,\n",
    ") = palette_techs\n",
    "\n",
    "# renaming technologies for plotting\n",
    "clean_chargers = [tech.replace(\" \", \"_\") for tech in storage_charge_techs]\n",
    "clean_dischargers = [tech.replace(\" \", \"_\") for tech in storage_discharge_techs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_ci_capacity = pd.Series(\n",
    "    {\n",
    "        \"onwind\": \"onshore wind\",\n",
    "        \"solar\": \"solar\",\n",
    "        \"battery_discharger\": \"battery\",\n",
    "        \"H2_Fuel_Cell\": \"hydrogen fuel cell\",\n",
    "        \"H2_Electrolysis\": \"hydrogen electrolysis\",\n",
    "        \"adv_geothermal\": \"advanced dispatchable\",\n",
    "        \"allam_ccs\": \"NG-Allam\",\n",
    "    }\n",
    ")\n",
    "\n",
    "rename_scen = {\n",
    "    \"0\": \"0%\\n\",\n",
    "    \"10\": \"10%\\n\",\n",
    "    \"20\": \"20%\\n\",\n",
    "    \"30\": \"30%\\n\",\n",
    "    \"40\": \"40%\\n\",\n",
    "}\n",
    "\n",
    "preferred_order = pd.Index(\n",
    "    [\n",
    "        \"advanced dispatchable\",\n",
    "        \"NG-Allam\",\n",
    "        \"Gas OC\",\n",
    "        \"offshore wind\",\n",
    "        \"onshore wind\",\n",
    "        \"solar\",\n",
    "        \"battery\",\n",
    "        \"hydrogen storage\",\n",
    "        \"hydrogen electrolysis\",\n",
    "        \"hydrogen fuel cell\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "rename_ci_cost = pd.Series(\n",
    "    {\n",
    "        \"onwind\": \"onshore wind\",\n",
    "        \"solar\": \"solar\",\n",
    "        \"grid\": \"grid imports\",\n",
    "        \"revenue\": \"revenue\",\n",
    "        \"battery_storage\": \"battery\",\n",
    "        \"battery_inverter\": \"battery\",\n",
    "        \"battery_discharger\": \"battery\",\n",
    "        \"hydrogen_storage\": \"hydrogen storage\",\n",
    "        \"hydrogen_electrolysis\": \"hydrogen storage\",\n",
    "        \"hydrogen_fuel_cell\": \"hydrogen storage\",\n",
    "        \"adv_geothermal\": \"advanced dispatchable\",\n",
    "        \"allam_ccs\": \"NG-Allam\",\n",
    "    }\n",
    ")\n",
    "\n",
    "rename = {\n",
    "    f\"{name} {suffix}\": category\n",
    "    for name in names\n",
    "    for suffix, category in {\n",
    "        \"H2 Electrolysis\": \"hydrogen storage\",\n",
    "        \"H2 Fuel Cell\": \"hydrogen storage\",\n",
    "        \"battery charger\": \"battery storage\",\n",
    "        \"battery discharger\": \"battery storage\",\n",
    "        \"export\": \"grid\",\n",
    "        \"import\": \"grid\",\n",
    "        \"onwind\": \"wind\",\n",
    "        \"solar\": \"solar\",\n",
    "        \"load\": \"load\",\n",
    "        \"adv_geothermal\": \"clean dispatchable\",\n",
    "        \"allam_ccs\": \"NG-Allam\",\n",
    "        \"DSM-delayout\": \"temporal shift\",\n",
    "        \"DSM-delayin\": \"temporal shift\",\n",
    "    }.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_colors = snakemake.config[\"tech_colors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots to be used in the dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot 1\n",
    "\n",
    "\n",
    "def assign_location(n):\n",
    "    \"\"\"\n",
    "    Assign bus location per each individual component\n",
    "    \"\"\"\n",
    "    for c in n.iterate_components(n.one_port_components | n.branch_components):\n",
    "        ifind = pd.Series(c.df.index.str.find(\" \", start=4), c.df.index)\n",
    "        for i in ifind.value_counts().index:\n",
    "            # these have already been assigned defaults\n",
    "            if i == -1:\n",
    "                continue\n",
    "            names = ifind.index[ifind == i]\n",
    "            c.df.loc[names, \"location\"] = names.str[:i]\n",
    "\n",
    "\n",
    "def plot_datacenters_on_europe_map(ax, network, datacenters):\n",
    "    projection = ccrs.PlateCarree()\n",
    "    # fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={\"projection\": projection})\n",
    "\n",
    "    ax.set_extent([-15, 30, 30, 70], crs=ccrs.PlateCarree())\n",
    "\n",
    "    map_opts = {\n",
    "        \"color_geomap\": {\n",
    "            \"ocean\": \"lightblue\",\n",
    "            \"land\": \"white\",\n",
    "            \"border\": \"black\",\n",
    "            \"coastline\": \"black\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Add map features with custom styles\n",
    "    ax.add_feature(\n",
    "        cfeature.OCEAN.with_scale(\"50m\"),\n",
    "        facecolor=map_opts[\"color_geomap\"][\"ocean\"],\n",
    "        zorder=0,\n",
    "    )\n",
    "    ax.add_feature(\n",
    "        cfeature.LAND.with_scale(\"50m\"),\n",
    "        facecolor=map_opts[\"color_geomap\"][\"land\"],\n",
    "        zorder=0,\n",
    "    )\n",
    "    ax.add_feature(\n",
    "        cfeature.BORDERS.with_scale(\"50m\"),\n",
    "        edgecolor=map_opts[\"color_geomap\"][\"border\"],\n",
    "        linewidth=0.5,\n",
    "        alpha=0.5,\n",
    "        zorder=1,\n",
    "    )\n",
    "    ax.add_feature(\n",
    "        cfeature.COASTLINE.with_scale(\"50m\"),\n",
    "        edgecolor=map_opts[\"color_geomap\"][\"coastline\"],\n",
    "        linewidth=0.5,\n",
    "        alpha=0.5,\n",
    "        zorder=1,\n",
    "    )\n",
    "\n",
    "    n = network.copy()\n",
    "    assign_location(n)\n",
    "\n",
    "    n.buses.drop(n.buses.index[n.buses.carrier != \"AC\"], inplace=True)\n",
    "    n.stores.drop(n.stores[n.stores.index.str.contains(\"EU\")].index, inplace=True)\n",
    "    n.links.drop(n.links[n.links.carrier == \"dsm\"].index, inplace=True)\n",
    "\n",
    "    dc_locations = n.buses.loc[datacenters.keys(), [\"x\", \"y\"]]\n",
    "\n",
    "    ax.scatter(\n",
    "        dc_locations[\"x\"],\n",
    "        dc_locations[\"y\"],\n",
    "        color=\"darkblue\",\n",
    "        # label=\"Datacenter locations\",\n",
    "        transform=ccrs.Geodetic(),\n",
    "        zorder=5,\n",
    "        s=100,\n",
    "    )\n",
    "    ax.set_title(\"Datacenter locations\", fontsize=14)\n",
    "\n",
    "    connections = set()\n",
    "    for i, loc1 in dc_locations.iterrows():\n",
    "        for j, loc2 in dc_locations.iterrows():\n",
    "            if i < j:  # each pair is considered only once\n",
    "                ax.plot(\n",
    "                    [loc1[\"x\"], loc2[\"x\"]],\n",
    "                    [loc1[\"y\"], loc2[\"y\"]],\n",
    "                    color=\"darkblue\",\n",
    "                    linestyle=\"dotted\",\n",
    "                    alpha=0.8,\n",
    "                    transform=ccrs.Geodetic(),\n",
    "                    zorder=4,\n",
    "                    linewidth=2,\n",
    "                )\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.legend(loc=\"lower left\")\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    # fig.savefig(\n",
    "    #     snakemake.output.plot_DC,\n",
    "    #     facecolor=\"white\",\n",
    "    #     dpi=600,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pearson_correlation_falloff(network, carrier, base_region):\n",
    "    \"\"\"\n",
    "    Computes the Pearson correlation coefficient between the p_max_pu time series\n",
    "    of a specified base region for a given carrier and all other regions.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with each region and its correlation coefficient with the base region.\n",
    "    \"\"\"\n",
    "\n",
    "    feedin = network.generators_t.p_max_pu.filter(like=carrier)\n",
    "\n",
    "    base_series = feedin[f\"{base_region} {carrier}\"]\n",
    "\n",
    "    correlations = []\n",
    "    for region in feedin.columns:\n",
    "        other_series = feedin[region]\n",
    "        correlation = base_series.corr(other_series)\n",
    "\n",
    "        region_name = \" \".join(region.split()[:-1])\n",
    "        correlations.append((region_name, correlation))\n",
    "\n",
    "    correlation_df = pd.DataFrame(correlations, columns=[\"Region\", \"Correlation\"])\n",
    "    return correlation_df.sort_values(\"Correlation\", ascending=False)\n",
    "\n",
    "\n",
    "# correlation_df = compute_pearson_correlation_falloff(n, \"onwind\", \"DK1 0\")\n",
    "# print(correlation_df)\n",
    "\n",
    "\n",
    "def plot_pearson_falloff(\n",
    "    ax, regions, network, carrier, base_region, colormap=\"viridis\"\n",
    "):\n",
    "    data = compute_pearson_correlation_falloff(network, carrier, base_region)\n",
    "\n",
    "    merged_data = regions.merge(data, left_on=\"name\", right_on=\"Region\", how=\"left\")\n",
    "\n",
    "    # fig, ax = plt.subplots(\n",
    "    #     subplot_kw={\"projection\": ccrs.PlateCarree()}, figsize=(10, 8)\n",
    "    # )\n",
    "\n",
    "    ax.set_extent([-15, 30, 35, 60], crs=ccrs.PlateCarree())\n",
    "\n",
    "    map_opts = {\n",
    "        \"color_geomap\": {\n",
    "            \"ocean\": \"lightblue\",\n",
    "            \"land\": \"white\",\n",
    "            \"border\": \"black\",\n",
    "            \"coastline\": \"black\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Add map features with custom styles\n",
    "    ax.add_feature(\n",
    "        cfeature.OCEAN.with_scale(\"50m\"),\n",
    "        facecolor=map_opts[\"color_geomap\"][\"ocean\"],\n",
    "        zorder=0,\n",
    "    )\n",
    "    ax.add_feature(\n",
    "        cfeature.LAND.with_scale(\"50m\"),\n",
    "        facecolor=map_opts[\"color_geomap\"][\"land\"],\n",
    "        zorder=0,\n",
    "    )\n",
    "    ax.add_feature(\n",
    "        cfeature.BORDERS.with_scale(\"50m\"),\n",
    "        edgecolor=map_opts[\"color_geomap\"][\"border\"],\n",
    "        linewidth=0.02,\n",
    "        alpha=0.3,\n",
    "        zorder=1,\n",
    "        rasterized=True,\n",
    "    )\n",
    "    ax.add_feature(\n",
    "        cfeature.COASTLINE.with_scale(\"50m\"),\n",
    "        edgecolor=map_opts[\"color_geomap\"][\"coastline\"],\n",
    "        linewidth=0.02,\n",
    "        alpha=0.3,\n",
    "        zorder=1,\n",
    "        rasterized=True,\n",
    "    )\n",
    "\n",
    "    merged_data.plot(\n",
    "        column=\"Correlation\",\n",
    "        ax=ax,\n",
    "        legend=False,\n",
    "        cmap=colormap,\n",
    "        linewidth=0.1,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "\n",
    "    norm = matplotlib.colors.Normalize(\n",
    "        vmin=0,\n",
    "        vmax=merged_data[\"Correlation\"].max(),\n",
    "    )\n",
    "    sm = matplotlib.cm.ScalarMappable(cmap=colormap, norm=norm)\n",
    "    sm.set_array([])  # You need this line for the colorbar to work with ScalarMappable.\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(\n",
    "        sm, ax=ax, orientation=\"horizontal\", fraction=0.05, pad=0.01\n",
    "    )\n",
    "\n",
    "    if carrier == \"onwind\":\n",
    "        _ = \"onshore wind\"\n",
    "    if carrier == \"solar\":\n",
    "        _ = \"solar PV\"\n",
    "\n",
    "    ax.coastlines()\n",
    "    ax.set_title(\n",
    "        f\"Wind correlation (Pearson's r) falloff with distance \\n\"\n",
    "        f\"data: {_} hourly capacity factor; base region: {base_region.split()[0]}\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    # plt.show()\n",
    "    # plt.savefig(\n",
    "    #     f\"../manuscript/img/pearson_corr_falloff_{carrier}_{base_region}.pdf\",\n",
    "    #     bbox_inches=\"tight\",\n",
    "    #     transparent=True,\n",
    "    # )\n",
    "\n",
    "\n",
    "# plot_pearson_falloff(\n",
    "#     ax, regions, network=n_256, carrier=\"solar\", base_region=\"PT1 0\", colormap=\"magma\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define technologies list\n",
    "techs = clean_techs + [\n",
    "    \"grid\",\n",
    "    \"battery_storage\",\n",
    "    \"battery_inverter\",\n",
    "    \"hydrogen_storage\",\n",
    "    \"hydrogen_electrolysis\",\n",
    "    \"hydrogen_fuel_cell\",\n",
    "]\n",
    "\n",
    "# Calculate costs and handle DataFrame operations\n",
    "costs = (\n",
    "    df.loc[[\"ci_cost_\" + t.replace(\" \", \"_\") for t in techs]]\n",
    "    .rename({\"ci_cost_\" + t: t for t in techs})\n",
    "    .multiply(1 / df.loc[\"ci_demand_total\"], axis=1)\n",
    ")\n",
    "costs = costs.drop(costs.index[(costs < 0.1).all(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 4\n",
    "\n",
    "\n",
    "def format_column_names(col_tuple):\n",
    "    return f\"{col_tuple[0]}{col_tuple[1][:2]}\"\n",
    "\n",
    "\n",
    "def ci_capacity(\n",
    "    ax, df, tech_colors, rename_scen, rename_ci_capacity, preferred_order, datacenters\n",
    "):\n",
    "    # fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Consolidate DataFrame operations\n",
    "    inventory_frames = [\n",
    "        df.loc[[\"ci_cap_\" + t.replace(\" \", \"_\") for t in techs]].rename(\n",
    "            {\"ci_cap_\" + t: t for t in techs}\n",
    "        )\n",
    "        for techs in [clean_techs, clean_dischargers, clean_chargers]\n",
    "    ]\n",
    "    ldf = pd.concat(inventory_frames)\n",
    "    ldf = ldf.drop([\"battery_charger\"])  # Exclude battery charger capacity\n",
    "\n",
    "    # Drop rows with all values less ran 0.1\n",
    "    ldf = ldf.drop(ldf.index[(ldf < 0.1).all(axis=1)])\n",
    "\n",
    "    # Rename columns and indices, and reorder DataFrame\n",
    "    ldf.rename(columns=rename_scen, level=0, inplace=True)\n",
    "    ldf.rename(index=rename_ci_capacity, level=0, inplace=True)\n",
    "    new_index = preferred_order.intersection(ldf.index).append(\n",
    "        ldf.index.difference(preferred_order)\n",
    "    )\n",
    "    ldf = ldf.loc[new_index].sort_index(\n",
    "        axis=\"columns\", level=[1, 0], ascending=[False, True]\n",
    "    )\n",
    "\n",
    "    # Plotting\n",
    "    if not ldf.empty:\n",
    "        ldf.T.plot(\n",
    "            kind=\"bar\",\n",
    "            stacked=True,\n",
    "            ax=ax,\n",
    "            color=tech_colors,\n",
    "            width=0.65,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.05,\n",
    "        )\n",
    "        ax.set_xticklabels(\n",
    "            [format_column_names(col) for col in ldf.columns.tolist()], fontsize=14\n",
    "        )\n",
    "        plt.xticks(rotation=0)\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.set_axisbelow(True)\n",
    "        # ax.set_ylim([0, max(ldf.sum()) * 1.3])\n",
    "        ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.0f\"))\n",
    "        ax.set_title(\"Portfolio capacity for 24/7 CFE matching\", fontsize=14)\n",
    "        ax.set_ylabel(\"Procured capacity [MW]\", fontsize=14)\n",
    "        ax.set_yticklabels([\"{:,.0f}\".format(x) for x in ax.get_yticks()], fontsize=14)\n",
    "        ax.legend(loc=\"upper right\", ncol=3, prop={\"size\": 12})\n",
    "\n",
    "        # Add datacenter lines\n",
    "        space = len(ldf.columns) / len(datacenters)\n",
    "        for l in range(len(datacenters) - 1):\n",
    "            ax.axvline(x=(space - 0.5) + space * l, color=\"gray\", linestyle=\"--\")\n",
    "    else:\n",
    "        print(\"Dataframe to plot is empty\")\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    # fig.savefig(snakemake.output.plot, transparent=True)\n",
    "\n",
    "\n",
    "def ci_costandrev(\n",
    "    ax, df, tech_colors, rename_scen, rename_ci_cost, preferred_order, datacenters\n",
    "):\n",
    "    # fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Define technologies list\n",
    "    techs = clean_techs + [\n",
    "        \"grid\",\n",
    "        \"battery_storage\",\n",
    "        \"battery_inverter\",\n",
    "        \"hydrogen_storage\",\n",
    "        \"hydrogen_electrolysis\",\n",
    "        \"hydrogen_fuel_cell\",\n",
    "    ]\n",
    "\n",
    "    # Calculate costs and handle DataFrame operations\n",
    "    costs = (\n",
    "        df.loc[[\"ci_cost_\" + t.replace(\" \", \"_\") for t in techs]]\n",
    "        .rename({\"ci_cost_\" + t: t for t in techs})\n",
    "        .multiply(1 / df.loc[\"ci_demand_total\"], axis=1)\n",
    "    )\n",
    "    costs = costs.drop(costs.index[(costs < 0.1).all(axis=1)])\n",
    "\n",
    "    # Handling revenues\n",
    "    revenues = -df.loc[[\"ci_average_revenue\"]].rename({\"ci_average_revenue\": \"revenue\"})\n",
    "    ldf = pd.concat([costs, revenues])\n",
    "\n",
    "    # Rename and Group by rename_ci_cost, then sort\n",
    "    ldf.rename(columns=rename_scen, level=0, inplace=True)\n",
    "    ldf = ldf.groupby(rename_ci_cost).sum()\n",
    "    new_index = [\"onshore wind\", \"solar\", \"battery\"]\n",
    "    ldf = ldf.loc[new_index].sort_index(\n",
    "        axis=\"columns\", level=[1, 0], ascending=[False, True]\n",
    "    )\n",
    "\n",
    "    # Plotting\n",
    "    if not ldf.empty:\n",
    "        ldf.T.plot(\n",
    "            kind=\"bar\",\n",
    "            stacked=True,\n",
    "            ax=ax,\n",
    "            color=tech_colors,\n",
    "            width=0.65,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.05,\n",
    "        )\n",
    "        ax.set_xticklabels(\n",
    "            [format_column_names(col) for col in ldf.columns.tolist()], fontsize=14\n",
    "        )\n",
    "        plt.xticks(rotation=0)\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.set_ylabel(\"Normalised costs [€$\\cdot$MWh$^{-1}$]\", fontsize=14)\n",
    "        ax.set_yticklabels([\"{:,.0f}\".format(x) for x in ax.get_yticks()], fontsize=14)\n",
    "        ax.set_title(\"Costs of 24/7 CFE matching\", fontsize=14)\n",
    "        ax.legend(loc=\"upper left\", ncol=3, prop={\"size\": 12})\n",
    "        # ax.set_ylim(top=max(ldf.sum()) * 1.3)\n",
    "\n",
    "        # # Add net cost markers\n",
    "        # net_costs = ldf.sum()\n",
    "        # for i, cost in enumerate(net_costs):\n",
    "        #     ax.scatter(x=i, y=cost, color=\"black\", marker=\"_\")\n",
    "        # ax.scatter([], [], color=\"black\", marker=\"_\", label=\"net cost\")\n",
    "        # ax.legend(loc=\"upper left\", ncol=1, prop={\"size\": 12})\n",
    "\n",
    "        # Add datacenter lines\n",
    "        space = len(ldf.columns) / len(datacenters)\n",
    "        for l in range(len(datacenters) - 1):\n",
    "            ax.axvline(x=(space - 0.5) + space * l, color=\"gray\", linestyle=\"--\")\n",
    "    else:\n",
    "        print(\"Dataframe to plot is empty\")\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    # fig.savefig(\n",
    "    #     snakemake.output.plot.replace(\"capacity.pdf\", \"ci_costandrev.pdf\"),\n",
    "    #     transparent=True,\n",
    "    # )\n",
    "\n",
    "\n",
    "def ci_abs_costs(ax, df, rename_scen):\n",
    "    # fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "\n",
    "    # Calculate absolute costs\n",
    "    ldf = (df.loc[\"ci_total_cost\"] - df.loc[\"ci_revenue_grid\"]) / 1e6\n",
    "    ldf = ldf.to_frame(name=\"ci_abs_costs\")\n",
    "\n",
    "    # Refine data\n",
    "    ldf.index = ldf.index.set_levels(ldf.index.levels[0].map(rename_scen), level=0)\n",
    "    ldf = ldf[\"ci_abs_costs\"].unstack()\n",
    "    ldf.sort_index(axis=\"rows\", ascending=True, inplace=True)\n",
    "\n",
    "    # Update columns for plotting\n",
    "    ldf.columns = [format_column_names(col) for col in ldf.columns.tolist()]\n",
    "\n",
    "    # Get the 'viridis' colormap\n",
    "    cmap = plt.get_cmap(\"viridis\")\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, len(ldf.columns))]\n",
    "\n",
    "    # Plotting\n",
    "    if not ldf.empty:\n",
    "        ldf.plot(\n",
    "            kind=\"bar\",\n",
    "            stacked=True,\n",
    "            ax=ax,\n",
    "            width=0.65,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.05,\n",
    "            color=colors,\n",
    "        )\n",
    "        plt.xticks(rotation=0)\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        # Additional calculations and horizontal lines\n",
    "        value = ldf.sum(axis=1)[0] - ldf.sum(axis=1)[-1]\n",
    "        percent_reduction = int(round(value / ldf.sum(axis=1)[0] * 100, 0))\n",
    "        ax.set_title(f\"Total annual costs reduction with flexibility\", fontsize=14)\n",
    "        for y_val in ldf.sum(axis=1):\n",
    "            ax.hlines(\n",
    "                y_val,\n",
    "                ax.get_xlim()[0],\n",
    "                ax.get_xlim()[1],\n",
    "                color=\"gray\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=1.5,\n",
    "                alpha=0.8,\n",
    "            )\n",
    "\n",
    "        ax.set_ylabel(\"Total annual costs [M€$\\cdot$year$^{-1}$]\", fontsize=14)\n",
    "        ax.set_yticklabels([\"{:,.0f}\".format(x) for x in ax.get_yticks()], fontsize=14)\n",
    "        ax.set_xticklabels(ldf.index, fontsize=14)\n",
    "        ax.legend(loc=\"lower left\", ncol=1, prop={\"size\": 12})\n",
    "\n",
    "        # Add second y-axis for relative costs\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.set_ylim(ax.get_ylim())\n",
    "        max_y_val = ldf.sum(axis=1)[0]\n",
    "        ax2.set_yticks(np.linspace(0, max_y_val, 11))\n",
    "        ax2.set_ylabel(f\"Relative costs [%]\", fontsize=14)\n",
    "        vals = ax2.get_yticks()\n",
    "        ax2.set_yticklabels(\n",
    "            [\"{:,.0%}\".format(x / max_y_val) for x in vals], fontsize=14\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(\"Dataframe to plot is empty\")\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    # fig.savefig(\n",
    "    #     snakemake.output.plot.replace(\"capacity.pdf\", \"ci_abs_costs.pdf\"),\n",
    "    #     transparent=True,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define technologies list\n",
    "techs = clean_techs + [\n",
    "    \"grid\",\n",
    "    \"battery_storage\",\n",
    "    \"battery_inverter\",\n",
    "    \"hydrogen_storage\",\n",
    "    \"hydrogen_electrolysis\",\n",
    "    \"hydrogen_fuel_cell\",\n",
    "]\n",
    "\n",
    "# Calculate costs and handle DataFrame operations\n",
    "costs = (\n",
    "    df.loc[[\"ci_cost_\" + t.replace(\" \", \"_\") for t in techs]]\n",
    "    .rename({\"ci_cost_\" + t: t for t in techs})\n",
    "    .multiply(1 / df.loc[\"ci_demand_total\"], axis=1)\n",
    ")\n",
    "costs = costs.drop(costs.index[(costs < 0.1).all(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"viridis\")\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, 5)]\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmaps\n",
    "\n",
    "\n",
    "def retrieve_nb(n, node):\n",
    "    \"\"\"\n",
    "    Retrieve nodal energy balance per hour\n",
    "        -> lines and links are bidirectional AND their subsets are exclusive.\n",
    "        -> links include fossil gens\n",
    "    NB {-1} multiplier is a nodal balance sign\n",
    "    \"\"\"\n",
    "\n",
    "    components = [\"Generator\", \"Load\", \"StorageUnit\", \"Store\", \"Link\", \"Line\"]\n",
    "    nodal_balance = pd.DataFrame(index=n.snapshots)\n",
    "\n",
    "    for i in components:\n",
    "        if i == \"Generator\":\n",
    "            node_generators = n.generators.query(\"bus==@node\").index\n",
    "            nodal_balance = nodal_balance.join(n.generators_t.p[node_generators])\n",
    "        if i == \"Load\":\n",
    "            node_loads = n.loads.query(\"bus==@node\").index\n",
    "            nodal_balance = nodal_balance.join(-1 * n.loads_t.p_set[node_loads])\n",
    "        if i == \"Link\":\n",
    "            node_export_links = n.links.query(\"bus0==@node\").index\n",
    "            node_import_links = n.links.query(\"bus1==@node\").index\n",
    "            nodal_balance = nodal_balance.join(-1 * n.links_t.p0[node_export_links])\n",
    "            nodal_balance = nodal_balance.join(-1 * n.links_t.p1[node_import_links])\n",
    "            ##################\n",
    "        if i == \"StorageUnit\":\n",
    "            # node_storage_units = n.storage_units.query('bus==@node').index\n",
    "            # nodal_balance = nodal_balance.join(n.storage_units_t.p_dispatch[node_storage_units])\n",
    "            # nodal_balance = nodal_balance.join(n.storage_units_t.p_store[node_storage_units])\n",
    "            continue\n",
    "        if i == \"Line\":\n",
    "            continue\n",
    "        if i == \"Store\":\n",
    "            continue\n",
    "\n",
    "    nodal_balance = nodal_balance.rename(columns=rename).groupby(level=0, axis=1).sum()\n",
    "\n",
    "    # Custom groupby function\n",
    "    def custom_groupby(column_name):\n",
    "        if column_name.startswith(\"vcc\"):\n",
    "            return \"spatial shift\"\n",
    "        return column_name\n",
    "\n",
    "    # Apply custom groupby function\n",
    "    nodal_balance = nodal_balance.groupby(custom_groupby, axis=1).sum()\n",
    "\n",
    "    # revert nodal balance sign for display\n",
    "    if \"spatial shift\" in nodal_balance.columns:\n",
    "        nodal_balance[\"spatial shift\"] = nodal_balance[\"spatial shift\"] * -1\n",
    "    if \"temporal shift\" in nodal_balance.columns:\n",
    "        nodal_balance[\"temporal shift\"] = nodal_balance[\"temporal shift\"] * -1\n",
    "\n",
    "    return nodal_balance\n",
    "\n",
    "\n",
    "def prepare_heatmap_shifts(shift_type, location, scaling):\n",
    "    year = 2013\n",
    "    data = (\n",
    "        retrieve_nb(n, node=f\"{location}\").get(f\"{shift_type}\") * -1\n",
    "    )  # NB REVERTING SIGN\n",
    "\n",
    "    days = np.arange(1, 366)\n",
    "    num_days = 365  # Correct number of days for a non-leap year\n",
    "    values = np.empty((int(24 / scaling), num_days))\n",
    "    values[:] = np.NaN  # Fill with NaNs as a default value\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        month_data = data[data.index.month == month]\n",
    "        for day in month_data.index.day.unique():\n",
    "            day_idx = (\n",
    "                sum([calendar.monthrange(year, m)[1] for m in range(1, month)])\n",
    "                + day\n",
    "                - 1\n",
    "            )  # Adjusting day_idx to be zero-indexed\n",
    "            day_values = month_data[month_data.index.day == day].values\n",
    "            try:\n",
    "                # Ensuring day_values is a 1D array before assignment\n",
    "                values[:, day_idx] = day_values.squeeze()\n",
    "            except ValueError as e:\n",
    "                print(f\"Error processing day {day} of month {month}: {e}\")\n",
    "\n",
    "    return days, values\n",
    "\n",
    "\n",
    "def draw_heatmap(ax, day, value, scaling, colormap, min_val, max_val):\n",
    "    xgrid = np.arange(day.max() + 1) + 1  # for days\n",
    "    ygrid = np.arange(int(24 / scaling) + 1)  # for hours\n",
    "\n",
    "    # Ensure the dimensions of 'value' match the expected dimensions for 'xgrid' and 'ygrid'\n",
    "    if value.shape != (len(ygrid) - 1, len(xgrid) - 1):\n",
    "        raise ValueError(\n",
    "            f\"Shape of value ({value.shape}) does not match xgrid ({len(xgrid)}) and ygrid ({len(ygrid)}) dimensions.\"\n",
    "        )\n",
    "\n",
    "    ax.pcolormesh(xgrid, ygrid, value, cmap=colormap, vmin=min_val, vmax=max_val)\n",
    "    ax.set_ylim(int(24 / scaling), 0)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def add_custom_annotations(ax):\n",
    "    ax.text(\n",
    "        -0.005,\n",
    "        0.25,\n",
    "        \"Hour of the Day\",\n",
    "        transform=ax.transAxes,\n",
    "        rotation=\"vertical\",\n",
    "        ha=\"right\",\n",
    "        va=\"center\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    ax.text(\n",
    "        0.1,\n",
    "        -0.01,\n",
    "        \"Day of the Year\",\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"center\",\n",
    "        va=\"top\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_heatmap_shifts(\n",
    "    fig,\n",
    "    ax,\n",
    "    shift_type,\n",
    "    location,\n",
    "    scaling,\n",
    "    colormap,\n",
    "    min_val,\n",
    "    max_val,\n",
    "):\n",
    "    # fig, axes = plt.subplots(1, 12, figsize=figsize, sharey=True)\n",
    "    # plt.tight_layout()\n",
    "\n",
    "    add_custom_annotations(ax)\n",
    "\n",
    "    days, value = prepare_heatmap_shifts(shift_type, location, scaling)\n",
    "\n",
    "    draw_heatmap(ax, days, value, scaling, colormap, min_val, max_val)\n",
    "\n",
    "    ax.set_title(f\"{location} - {shift_type} \" + r\"[MWh·h$^{-1}$]\", fontsize=14, pad=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-in hourly diffs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = (\n",
    "    n.generators_t.p_max_pu.filter(regex=f\"{location0}|{location1}|{location2}\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"snapshot\"})\n",
    "    .assign(snapshot=lambda x: pd.to_datetime(x[\"snapshot\"]))\n",
    ")\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_heatmap_data(df, location, carrier, scaling, diff_location=None, year=2013):\n",
    "    # We only have 2013 weather year, but just in case.\n",
    "    data = df[df[\"snapshot\"].dt.year == year]\n",
    "\n",
    "    # Convert snapshot dates to day of the year\n",
    "    day_of_year = data[\"snapshot\"].dt.dayofyear\n",
    "    hours = data[\"snapshot\"].dt.hour\n",
    "\n",
    "    num_days = 366 if calendar.isleap(year) else 365\n",
    "    num_time_slots = int(24 / scaling)\n",
    "    value_matrix = np.zeros((num_time_slots, num_days))\n",
    "\n",
    "    for i, (day, hour) in enumerate(zip(day_of_year, hours)):\n",
    "        time_slot = int(hour // scaling)\n",
    "        day_index = day - 1  # Adjusting index to be zero-based\n",
    "        value = data[f\"{location} {carrier}\"].iloc[i]\n",
    "\n",
    "        if diff_location:\n",
    "            diff_value = data[f\"{diff_location} {carrier}\"].iloc[i]\n",
    "            value -= diff_value\n",
    "\n",
    "        value_matrix[\n",
    "            time_slot, day_index\n",
    "        ] += value  # Assuming aggregation, adjust as necessary\n",
    "\n",
    "    return np.arange(1, num_days + 1), value_matrix\n",
    "\n",
    "\n",
    "def draw_heatmap(ax, day, value, scaling, colormap, min_val, max_val):\n",
    "    xgrid = np.arange(day.max() + 1) + 1  # for days\n",
    "    ygrid = np.arange(int(24 / scaling) + 1)  # for hours\n",
    "\n",
    "    # Ensure the dimensions of 'value' match the expected dimensions for 'xgrid' and 'ygrid'\n",
    "    if value.shape != (len(ygrid) - 1, len(xgrid) - 1):\n",
    "        raise ValueError(\n",
    "            f\"Shape of value ({value.shape}) does not match xgrid ({len(xgrid)}) and ygrid ({len(ygrid)}) dimensions.\"\n",
    "        )\n",
    "\n",
    "    ax.pcolormesh(xgrid, ygrid, value, cmap=colormap, vmin=min_val, vmax=max_val)\n",
    "    ax.set_ylim(int(24 / scaling), 0)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def plot_heatmap_cf(\n",
    "    fig,\n",
    "    ax,\n",
    "    df,\n",
    "    location,\n",
    "    carrier,\n",
    "    scaling,\n",
    "    colormap,\n",
    "    MIN,\n",
    "    MAX,\n",
    "    year=2013,\n",
    "    plot_difference=False,\n",
    "    diff_location=None,\n",
    "):\n",
    "    # Removed the subplots creation and adjusted for a single ax usage\n",
    "    # Assuming prepare_heatmap_data now handles year-long data\n",
    "    day, value = prepare_heatmap_data(\n",
    "        df,\n",
    "        location,\n",
    "        carrier,\n",
    "        scaling,\n",
    "        diff_location=diff_location if plot_difference else None,\n",
    "    )\n",
    "    draw_heatmap(ax, day, value, scaling, colormap, MIN, MAX)\n",
    "\n",
    "    # Custom annotations\n",
    "    add_custom_annotations(ax)  # Use your existing function for custom annotations\n",
    "\n",
    "    if carrier == \"onwind\":\n",
    "        _ = \"onshore wind\"\n",
    "    if carrier == \"solar\":\n",
    "        _ = \"solar PV\"\n",
    "\n",
    "    # Title and Colorbar adjustments\n",
    "    ax.set_title(\n",
    "        f\"Difference between hourly capacity factors for {_}: {location} vs {diff_location}\",\n",
    "        fontsize=14,\n",
    "        pad=3,\n",
    "    )\n",
    "    # Assuming there's a mechanism to place colorbar in the dashboard layout\n",
    "\n",
    "    # # Additional annotations as per your requirements\n",
    "    # annotations = [\n",
    "    #     f\"Location: {location}\" if not plot_difference else f\"Location: {location} vs {diff_location}\",\n",
    "    #     f\"Carrier: {carrier}\",\n",
    "    #     f\"Weather Year: {year}\",\n",
    "    #     r\"Unit: MWh·h$^{-1}$\",\n",
    "    # ]\n",
    "    # # Adjust positioning as needed within your dashboard layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dashboard(network, datacenters, regions, colormap):\n",
    "    \"\"\"\n",
    "    Creates a dashboard for section 1: renewable resource quality\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    # plt.figure(figsize=(30, 50))\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 50))\n",
    "\n",
    "    # Define GridSpec: 5 rows, 6 columns\n",
    "    gs = gridspec.GridSpec(58, 6, hspace=1.5, wspace=0.3)\n",
    "\n",
    "    ax_map = plt.subplot(gs[16:30, :2], projection=ccrs.PlateCarree())\n",
    "    plot_datacenters_on_europe_map(\n",
    "        ax_map, network, datacenters\n",
    "    )  # Custom function for the map\n",
    "\n",
    "    ax_map_2 = plt.subplot(gs[0:30, 2:4], projection=ccrs.PlateCarree())\n",
    "    plot_pearson_falloff(\n",
    "        ax=ax_map_2,\n",
    "        regions=regions,\n",
    "        network=network,\n",
    "        carrier=\"solar\",\n",
    "        base_region=\"PT1 0\",\n",
    "        colormap=\"magma\",\n",
    "    )\n",
    "\n",
    "    ax_map_3 = plt.subplot(gs[0:30, 4:6], projection=ccrs.PlateCarree())\n",
    "    plot_pearson_falloff(\n",
    "        ax=ax_map_3,\n",
    "        regions=regions,\n",
    "        network=network,\n",
    "        carrier=\"solar\",\n",
    "        base_region=\"GR1 0\",\n",
    "        colormap=\"magma\",\n",
    "    )\n",
    "\n",
    "    heatmap_ax_1 = plt.subplot(gs[30:37, 0:3])\n",
    "    plot_heatmap_cf(\n",
    "        fig=fig,\n",
    "        ax=heatmap_ax_1,\n",
    "        df=ts,\n",
    "        location=\"Greece\",\n",
    "        carrier=\"solar\",\n",
    "        scaling=int(snakemake.config[\"time_sampling\"][0]),\n",
    "        colormap=\"PuOr\",\n",
    "        MIN=-1,\n",
    "        MAX=1,\n",
    "        diff_location=f\"Portugal\",\n",
    "        plot_difference=True,\n",
    "    )\n",
    "\n",
    "    heatmap_ax_2 = plt.subplot(gs[30:37, 3:6])\n",
    "    plot_heatmap_cf(\n",
    "        fig=fig,\n",
    "        ax=heatmap_ax_2,\n",
    "        df=ts,\n",
    "        location=\"Greece\",\n",
    "        carrier=\"onwind\",\n",
    "        scaling=int(snakemake.config[\"time_sampling\"][0]),\n",
    "        colormap=\"PuOr\",\n",
    "        MIN=-1,\n",
    "        MAX=1,\n",
    "        diff_location=f\"Portugal\",\n",
    "        plot_difference=True,\n",
    "    )\n",
    "    # Map plot\n",
    "    ax_bar = plt.subplot(gs[39:47, :2])\n",
    "    ci_capacity(\n",
    "        ax=ax_bar,\n",
    "        df=df,\n",
    "        tech_colors=tech_colors,\n",
    "        rename_scen=rename_scen,\n",
    "        rename_ci_capacity=rename_ci_capacity,\n",
    "        preferred_order=preferred_order,\n",
    "        datacenters=datacenters,\n",
    "    )\n",
    "\n",
    "    ax_bar = plt.subplot(gs[39:47, 2:4])\n",
    "    ci_costandrev(\n",
    "        ax=ax_bar,\n",
    "        df=df,\n",
    "        tech_colors=tech_colors,\n",
    "        rename_scen=rename_scen,\n",
    "        rename_ci_cost=rename_ci_cost,\n",
    "        preferred_order=preferred_order,\n",
    "        datacenters=datacenters,\n",
    "    )\n",
    "\n",
    "    ax_bar = plt.subplot(gs[39:47, 4:6])\n",
    "    ci_abs_costs(\n",
    "        ax=ax_bar,\n",
    "        df=df,\n",
    "        rename_scen=rename_scen,\n",
    "    )\n",
    "\n",
    "    # # # Map plot\n",
    "    heatmap_ax_3 = plt.subplot(gs[48:55, 0:3])\n",
    "    plot_heatmap_shifts(\n",
    "        fig=fig,\n",
    "        ax=heatmap_ax_3,\n",
    "        shift_type=\"spatial shift\",\n",
    "        location=\"Greece\",\n",
    "        scaling=1,\n",
    "        colormap=colormap,\n",
    "        min_val=-40.0,  # - int(flex)\n",
    "        max_val=+40.0,  # + int(flex)\n",
    "    )\n",
    "\n",
    "    heatmap_ax_4 = plt.subplot(gs[48:55, 3:6])\n",
    "    plot_heatmap_shifts(\n",
    "        fig=fig,\n",
    "        ax=heatmap_ax_4,\n",
    "        shift_type=\"spatial shift\",\n",
    "        location=\"Portugal\",\n",
    "        scaling=1,\n",
    "        colormap=colormap,\n",
    "        min_val=-40.0,  # - int(flex)\n",
    "        max_val=+40.0,  # + int(flex)\n",
    "    )\n",
    "\n",
    "    # a colorbar for capacity factor difference\n",
    "\n",
    "    cbar_ax = fig.add_axes(\n",
    "        [0.135, 0.375, 0.36, 0.006]\n",
    "    )  # These values may need adjustment\n",
    "    norm = mc.Normalize(vmin=-1.0, vmax=+1.0)\n",
    "    cb = fig.colorbar(\n",
    "        ScalarMappable(norm=norm, cmap=\"PuOr\"),\n",
    "        cax=cbar_ax,\n",
    "        orientation=\"horizontal\",\n",
    "    )\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "\n",
    "    fig.text(\n",
    "        0.52,\n",
    "        0.373,\n",
    "        \"Positive values imply higher capacity factor in Greece\",\n",
    "        ha=\"left\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    fig.text(\n",
    "        0.52,\n",
    "        0.378,\n",
    "        \"Negative values imply higher capacity factor in Portugal\",\n",
    "        ha=\"left\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    # a colorbar for the heatmap shifts\n",
    "\n",
    "    cbar_ax = fig.add_axes(\n",
    "        [0.135, 0.132, 0.36, 0.006]\n",
    "    )  # These values may need adjustment\n",
    "    norm = mc.Normalize(vmin=-40.0, vmax=+40.0)\n",
    "    cb = fig.colorbar(\n",
    "        ScalarMappable(norm=norm, cmap=colormap),\n",
    "        cax=cbar_ax,\n",
    "        orientation=\"horizontal\",\n",
    "    )\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "\n",
    "    fig.text(\n",
    "        0.52,\n",
    "        0.13,\n",
    "        \"Positive values mapped to blue color represent increase of a load\",\n",
    "        ha=\"left\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    fig.text(\n",
    "        0.52,\n",
    "        0.135,\n",
    "        \"Negative values mapped to red color represent decrease of a load\",\n",
    "        ha=\"left\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    fig.text(0.11, 0.64, \"a\", ha=\"left\", fontsize=20, fontweight=\"bold\")\n",
    "    fig.text(0.38, 0.645, \"b\", ha=\"left\", fontsize=20, fontweight=\"bold\")\n",
    "    fig.text(0.65, 0.645, \"c\", ha=\"left\", fontsize=20, fontweight=\"bold\")\n",
    "    fig.text(0.11, 0.48, \"d\", ha=\"left\", fontsize=20, fontweight=\"bold\")\n",
    "    fig.text(0.515, 0.48, \"e\", ha=\"left\", fontsize=20, fontweight=\"bold\")\n",
    "    fig.text(0.11, 0.36, \"f\", ha=\"left\", fontsize=20, fontweight=\"bold\")\n",
    "    fig.text(0.38, 0.36, \"g\", ha=\"left\", fontsize=20, fontweight=\"bold\")\n",
    "    fig.text(0.65, 0.36, \"h\", ha=\"left\", fontsize=20, fontweight=\"bold\")\n",
    "    fig.text(0.11, 0.235, \"i\", ha=\"left\", fontsize=20, fontweight=\"bold\")\n",
    "    fig.text(0.515, 0.235, \"j\", ha=\"left\", fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "    # plt.show()\n",
    "    fig.savefig(\n",
    "        \"../manuscript/img/dashboard_3.pdf\",\n",
    "        dpi=300,\n",
    "        transparent=True,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "\n",
    "create_dashboard(\n",
    "    network=n_256, datacenters=datacenters, regions=regions, colormap=\"RdBu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
